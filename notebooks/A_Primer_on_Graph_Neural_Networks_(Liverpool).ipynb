{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMznB6f8c2AZ7HAbYkWagYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessiodevoto/gnns_xai_liverpool/blob/main/notebooks/A_Primer_on_Graph_Neural_Networks_(Liverpool).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Primer on Graph Neural Networks\n",
        "\n",
        "**Author**: [Alessio Devoto](https://alessiodevoto.github.io/)\n",
        "\n",
        "This is an introductory tutorial to [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) a library for the design of deep Graph Neural Networks(GNNs). The first part is a re-adaptation of the documentation from the PyG website, training a GNN for graph classification on the [MUTAG](https://paperswithcode.com/dataset/mutag) dataset (using [PyTorch Lightning](https://www.pytorchlightning.ai/) for the training loop). The notebook is inspired by [Simone Scardapane](https://sscardapane.it/)'s material on GNNs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fVFfNAgTXTk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 🚗 Setup the colab environment\n"
      ],
      "metadata": {
        "id": "DMw3bMjxXJmu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVE0VxLzWxWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bec71d-9811-41f2-cf0c-c0ff3fef3ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/661.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m481.3/661.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=5d64e85b09568af6a5c59a2a63ec311d34d9739fd3b6551eb8018d9c95d90837\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/pyg_lib-0.2.0%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (627 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m627.0/627.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.2)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.2.0+pt20cpu torch_cluster-1.6.1+pt20cpu torch_scatter-2.1.1+pt20cpu torch_sparse-0.6.17+pt20cpu torch_spline_conv-1.2.2+pt20cpu\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# We use a cpu based installation for torch geometric\n",
        "# More info here https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html\n",
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "!pip install pytorch-lightning --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch imports\n",
        "import torch\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "snDMNC8dXxsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch-related imports\n",
        "import torch_geometric as ptgeom\n",
        "import torch_scatter, torch_sparse"
      ],
      "metadata": {
        "id": "kxnEIGQqXzHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as ptlight\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from torchmetrics.functional import accuracy"
      ],
      "metadata": {
        "id": "f-Nve9dgX0QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other imports\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fbDG7pWtX1uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['figure.dpi'] = 120 # I like higher resolution plots :)"
      ],
      "metadata": {
        "id": "hBL3YaENO1mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 💾 Data"
      ],
      "metadata": {
        "id": "0abc40IRzied"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Download & Explore Dataset\n",
        "\n",
        "Pytorch Geometric provides a number of datasets to use off-the-shelf, for all graph related tasks (graph, node or edge level tasks). Find a complete list [here](https://pytorch-geometric.readthedocs.io/en/latest/notes/data_cheatsheet.html).\n",
        "\n",
        "In this tutorial, we will use the **MUTAG** dataset. See the MUTAG page on [Papers With Code](https://paperswithcode.com/dataset/mutag) and related papers for more information about the dataset. This is a toy version, so we do not care too much about the final performance."
      ],
      "metadata": {
        "id": "axj8xUDaXcxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n"
      ],
      "metadata": {
        "id": "y8U7zySJXa8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful info stored in the dataset class"
      ],
      "metadata": {
        "id": "85t_FKtGY8Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Each graph in the dataset is represented as an instance of the generic Data object:\n",
        "# https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n"
      ],
      "metadata": {
        "id": "vWnCnx7fZP57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the meaning of each of these fields ?\n",
        "\n",
        "![](https://raw.githubusercontent.com/alessiodevoto/gnns_xai_liverpool/main/images/simple_graph_labels.png)"
      ],
      "metadata": {
        "id": "dZJY3JaEIw9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# node features\n"
      ],
      "metadata": {
        "id": "E3MhfSNLbFVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graph class (remember we only have two classes as this is a binary classfication problem)\n"
      ],
      "metadata": {
        "id": "gvkTBzYebIUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the adjacency matrix stored in COO format\n"
      ],
      "metadata": {
        "id": "n2WxLOP7blq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at the first 4 edges\n"
      ],
      "metadata": {
        "id": "Hd628r8Eb-ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inside utils (https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html)\n",
        "# there are a number of useful tools, e.g., we can check that the graph is undirected (the adjacency matrix is symmetric)\n"
      ],
      "metadata": {
        "id": "qgMmr1_EcP5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# are there self loops in this graph ?\n"
      ],
      "metadata": {
        "id": "30yhOuqidUYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# any isolated components ?\n"
      ],
      "metadata": {
        "id": "IKqHHyrUdWRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Data Visualization\n",
        "\n",
        "As always, it is crucial to visualize (if possible) the data structures we are dealing with.\n",
        "\n",
        "In the case of graphs, this can be prohibitive due to very high number of nodes. Luckily all our molecules are quite small.\n",
        "\n",
        "Let's define a simple function to plot a graph, using `matplotlib` and the `networkx` package"
      ],
      "metadata": {
        "id": "zboOmL_hduIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This one is copy-pasted from: https://colab.research.google.com/drive/1fLJbFPz0yMCQg81DdCP5I8jXw9LoggKO?usp=sharing\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from torch_geometric.utils import to_networkx\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# transform the pytorch geometric graph into networkx format\n",
        "def to_molecule(data: ptgeom.data.Data) -> nx.classes.digraph.DiGraph:\n",
        "    ATOM_MAP = ['C', 'O', 'Cl', 'H', 'N', 'F',\n",
        "                'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']\n",
        "    g = to_networkx(data, node_attrs=['x'])\n",
        "    for u, data in g.nodes(data=True):\n",
        "        data['name'] = ATOM_MAP[data['x'].index(1.0)]\n",
        "        del data['x']\n",
        "    return g\n",
        "\n",
        "# plot the molecule\n",
        "def draw_molecule(g, edge_mask=None, draw_edge_labels=True, draw_node_labels=True, ax=None, figsize=None):\n",
        "    figure(figsize = figsize or (4, 3))\n",
        "\n",
        "    # check if it's been already converted to a nx graph\n",
        "    if not isinstance(g, nx.classes.digraph.DiGraph):\n",
        "      g = to_molecule(g)\n",
        "\n",
        "    g = g.copy().to_undirected()\n",
        "    node_labels = {}\n",
        "    for u, data in g.nodes(data=True):\n",
        "        node_labels[u] = data['name']\n",
        "    pos = nx.planar_layout(g)\n",
        "    pos = nx.spring_layout(g, pos=pos)\n",
        "    if edge_mask is None:\n",
        "        edge_color = 'black'\n",
        "        widths = None\n",
        "    else:\n",
        "        edge_color = [edge_mask[(u, v)] for u, v in g.edges()]\n",
        "        widths = [x * 10 for x in edge_color]\n",
        "    nx.draw(g, pos=pos, labels=node_labels if draw_node_labels else None, width=widths,\n",
        "            edge_color=edge_color, edge_cmap=plt.cm.Blues,\n",
        "            node_color='azure')\n",
        "\n",
        "    if draw_edge_labels and edge_mask is not None:\n",
        "        edge_labels = {k: ('%.2f' % v) for k, v in edge_mask.items()}\n",
        "        nx.draw_networkx_edge_labels(g, pos, edge_labels=edge_labels,\n",
        "                                    font_color='red', ax=ax)\n",
        "\n",
        "    if ax is None:\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "HsqqRmf-dsqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot"
      ],
      "metadata": {
        "id": "NqmtHjJri6fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize some graphs { run: \"auto\" }\n",
        "mutag_idx = 6 # @param {type:\"slider\", min:0, max:187, step:1}\n",
        "\n",
        "draw_molecule(mutag[mutag_idx])\n"
      ],
      "metadata": {
        "id": "7x0BGRtznf5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3: Transformations\n",
        "\n",
        "Transformations are a quick way to include standard preprocessing when loading the graphs (e.g., automatically computing edge from the nodes positions). They work pretty much like torchvision's transforms.\n",
        "\n",
        "See the full list of available transformations here:\n",
        "\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html"
      ],
      "metadata": {
        "id": "q4hKhKzJrlMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As an experiment, we load the graph with a sparse adjacency format instead of the COO list"
      ],
      "metadata": {
        "id": "pChAOMiUt9I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The format has a number of useful methods that are already implemented: https://github.com/rusty1s/pytorch_sparse\n",
        "# For example, we can perform a single step of diffusion on the node features efficiently with a sparse-dense matrix multiplication"
      ],
      "metadata": {
        "id": "GlLxBEvLuCXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔥 **Warmup Exercise no. 1**\n",
        "\n",
        "Imagine you are a (probably crazy) chemist and you want to *add self loops* to all of the molecules in your dataset.\n",
        "\n",
        "What would you do? Plot a graph after adding self loops. Hint: [this transform](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.AddSelfLoops.html#torch_geometric.transforms.AddSelfLoops)"
      ],
      "metadata": {
        "id": "p8rSs8DvKP2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We load the graph and add self loops to all nodes (probably doesn't make sense from a chemical point of view 🤔)\n"
      ],
      "metadata": {
        "id": "X4z4O9bHtHl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Data loading\n",
        "\n",
        "Data loaders are a nice utility to automatically build mini-batches (either a subset of graphs, or a subgraph extracted from a single graph) from the dataset.\n",
        "\n",
        "\n",
        "Pytorch Geometric manages the batching by [stacking the adjacency matrices](https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html) into a single huge graph.\n",
        "\n"
      ],
      "metadata": {
        "id": "93RGXJTxXhv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plain MUTAG without self loops\n",
        "mutag = ptgeom.datasets.TUDataset(root='.', name='MUTAG')"
      ],
      "metadata": {
        "id": "zYA4d_5fws4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we split the original dataset into a training and test spart with a stratified split on the class\n",
        "train_idx, test_idx = train_test_split(range(len(mutag)), stratify=[m.y[0].item() for m in mutag], test_size=0.25, random_state=11)\n",
        "\n",
        "train_mutag = mutag[train_idx]\n",
        "test_mutag = mutag[test_idx]"
      ],
      "metadata": {
        "id": "q_F11aq_Xlf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the two loaders\n",
        "train_loader = ptgeom.loader.DataLoader(mutag[train_idx], batch_size=32, shuffle=True)\n",
        "test_loader = ptgeom.loader.DataLoader(mutag[test_idx], batch_size=32)"
      ],
      "metadata": {
        "id": "6R5pjoOXwYxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us inspect the first batch of data\n"
      ],
      "metadata": {
        "id": "DYoaE9cSwaOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The batch is built by considering all the subgraphs as a single giant graph with unconnected components\n",
        "# Let us explore some of the components of the batch\n",
        "\n"
      ],
      "metadata": {
        "id": "S3NDdEQEwbVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔥 **Warmup Exercise no. 2**\n",
        "\n",
        "As we said, PyTorch Geometric creates batches by stacking together small graphs into a single large one.\n",
        "\n",
        "Create a dataloader with batch_size = 2 and plot the first batch to check it's content."
      ],
      "metadata": {
        "id": "3JeCIGk9Lpsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't do this with large batch size"
      ],
      "metadata": {
        "id": "_DS1zCXAwkFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we built this new huge graph, how do we keep track of all the small subgraphs 🤔 ?\n",
        "# There is an additional property linking each node to its corresponding graph index\n",
        "# Print the batch"
      ],
      "metadata": {
        "id": "Og6S7HdtwduK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/alessiodevoto/gnns_xai_liverpool/main/images/batching.png)"
      ],
      "metadata": {
        "id": "OTOd3Sb1abv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can perform a graph-level average with torch_scatter, see the figure here for a visual explanation:\n",
        "# https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html\n"
      ],
      "metadata": {
        "id": "63Adk5aOyBYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively, PyG has this implemented as a functional layer in nn.global_mean_pool\n"
      ],
      "metadata": {
        "id": "2_0kpfFOyPSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 🪄 Design and train the Graph Neural Network\n",
        "\n",
        "We have explored the data and created the Dataloaders, which will help us during the training. We are finally able to build the model!"
      ],
      "metadata": {
        "id": "iNI8qpl8zUIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layers in PyG are very similar to PyTorch, e.g., this is a standard graph convolutional layer GCNConv\n"
      ],
      "metadata": {
        "id": "LZCJ-gukzZ3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pay attention to the forward arguments"
      ],
      "metadata": {
        "id": "sstljSCdzqz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different layers have different properties, see this \"cheatsheet\" from the documentation:\n",
        "# https://pytorch-geometric.readthedocs.io/en/latest/notes/cheatsheet.html\n",
        "# For example, GCNConv accepts an additional \"edge_weight\" parameter to weight each edge."
      ],
      "metadata": {
        "id": "nGT3Wa8zzs63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are not used to PyTorch Lightning, see the 5-minutes intro from here:\n",
        "# https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html\n",
        "\n",
        "train_losses = []\n",
        "eval_accs = []\n",
        "\n",
        "class MUTAGClassifier(ptlight.LightningModule):\n",
        "\n",
        "  def __init__(self, hidden_features: int):\n",
        "    super().__init__()\n",
        "    # Here go the layers\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index=None, batch=None, edge_weight=None):\n",
        "\n",
        "    # unwrap the graph if the whole Data object was passed\n",
        "    if edge_index is None:\n",
        "      x, edge_index, batch = x.x, x.edge_index, x.batch\n",
        "\n",
        "    # Here we process the input\n",
        "    # We go gcn -> F.relu -> mean_pool -> F.dropout -> Linear\n",
        "\n",
        "    return logits\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "      return optimizer\n",
        "\n",
        "\n",
        "  def training_step(self, batch, _):\n",
        "\n",
        "      # Training step\n",
        "\n",
        "      # Log loss\n",
        "\n",
        "      return loss\n",
        "\n",
        "  def validation_step(self, batch, _):\n",
        "\n",
        "    # Eval step\n",
        "\n",
        "    # Log accuracy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b_I8swk500yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the model\n",
        "model = MUTAGClassifier(256)\n",
        "model"
      ],
      "metadata": {
        "id": "mq4ZjfVU4MD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward one batch"
      ],
      "metadata": {
        "id": "06t7ynGk4DiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Training the model\n",
        "\n"
      ],
      "metadata": {
        "id": "VTEx7Repz3YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We save checkpoints every 50 epochs\n",
        "# This is like taking 'snapshots' of the model every 50 epochs\n",
        "# We will use this in the next notebook\n",
        "\n",
        "checkpoint_callback = ptlight.callbacks.ModelCheckpoint(\n",
        "    dirpath='./checkpoints/',\n",
        "    filename='gnn-{epoch:02d}',\n",
        "    every_n_epochs=50,\n",
        "    save_top_k=-1)"
      ],
      "metadata": {
        "id": "DUP46sbzz5B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the trainer\n",
        "trainer = ptlight.Trainer(\n",
        "    max_epochs=80,\n",
        "    callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "EEI2lWI_4YM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is not a particularly well-designed model, we expect approximately 80% test accuracy\n",
        "trainer.fit(model, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "udoI0sfx4ajr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple plots to visualize metrics\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(train_losses)\n",
        "plt.plot(eval_accs)\n",
        "\n",
        "plt.legend(['Loss', 'Accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nJZ04Ia9JqGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not working due to cookies settings in most cases\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=/content/lightning_logs"
      ],
      "metadata": {
        "id": "Hebnw1he6sKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 💪 Exercise time\n",
        "\n",
        "Pytorch geometric contains a wide range of possibilities for Graph Convolutional layers. You can find them [here](https://pytorch-geometric.readthedocs.io/en/latest/cheatsheet/gnn_cheatsheet.html).\n",
        "\n",
        "1. Instead of the simple `GCNConv` we used, build a model making use of different layers, e.g. the GATConv. Train the model and compare the results with the ones we obtained. Are they better or worse?\n",
        "\n",
        "2. (If we have time) Can we change the forward function of our model and also use edge weights. Is it beneficial for the training ?"
      ],
      "metadata": {
        "id": "1JNeYvJQ-X0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "# Keep track of metrics here\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "eval_accs = []\n",
        "\n",
        "# Define the new model\n",
        "class MyCoolGNN(ptlight.LightningModule):\n",
        "\n",
        "  def __init__(self, hidden_features: int, heads: int):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x, edge_index=None, batch=None, edge_weight=None):\n",
        "\n",
        "    # unwrap the graph if the whole Data object was passed\n",
        "    if edge_index is None:\n",
        "      x, edge_index, batch = x.x, x.edge_index, x.batch\n",
        "\n",
        "    return logits\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "      return optimizer\n",
        "\n",
        "\n",
        "  def training_step(self, batch, _):\n",
        "\n",
        "\n",
        "  def validation_step(self, batch, _):\n",
        "\n",
        "\n",
        "model = MyCoolGNN(256, 2)"
      ],
      "metadata": {
        "id": "v1b302_EOIBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on one batch\n"
      ],
      "metadata": {
        "id": "0ZF9IGxseUB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train (no callbacks needed this time)\n"
      ],
      "metadata": {
        "id": "eIhsSl0KhQRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the metrics\n"
      ],
      "metadata": {
        "id": "kc6XTdAXhYEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}